{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Add the directory containing the file 'secret_key.py' to the Python path\n",
        "import sys\n",
        "sys.path.append(\"/content/secret_key.py\")\n",
        "\n",
        "# Import the openapi_key variable from the secret_key.py file\n",
        "from secret_key import openapi_key\n",
        "\n",
        "# Set the OPENAI_API_KEY environment variable\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openapi_key"
      ],
      "metadata": {
        "id": "RUCnvjYAn9un"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0WcFBYQbNb4",
        "outputId": "d1b58344-4da7-4968-faad-a1d7e05d246c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0dAeiO_oYB1",
        "outputId": "16a74c5e-037f-47df-a2f0-051290544b47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.4-py3-none-any.whl (327 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/327.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z2Ydsb1oxIF",
        "outputId": "799f5822-34ea-4d04-b131-6c95a9ddce74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.6 (from langchain_community)\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.10 (from langchain_community)\n",
            "  Downloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.6->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (2.7.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain_community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langchain_community-0.2.6 langsmith-0.1.82 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Large Language Models (LLMs) like OpenAI's GPT models, \"temperature\" is a parameter that controls the randomness of the model's output. It influences the diversity of the generated text by adjusting the probability distribution of the next word or token in the sequence. (LLM doc)"
      ],
      "metadata": {
        "id": "hJYxiaPx7wci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.6)\n",
        "jk = llm(\"How can I improve my Gen AI skills?\")\n",
        "print(jk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wslF5WYyoj5e",
        "outputId": "fce22b01-e4c2-426a-e4e4-7f722be2dd79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Practice regularly: Like any other skill, practicing regularly is crucial for improving your Gen AI skills. Set aside some time each day to work on projects or explore new ideas using Gen AI tools.\n",
            "\n",
            "2. Read and learn from others: Keep up-to-date with the latest advancements in Gen AI by reading articles, blogs, and books written by experts in the field. This will help you gain new insights and ideas to improve your skills.\n",
            "\n",
            "3. Take online courses: There are many online courses available that can help you learn Gen AI techniques and tools. These courses offer structured learning and provide hands-on experience in using Gen AI tools.\n",
            "\n",
            "4. Join online communities: Join online communities and forums dedicated to Gen AI. These communities are a great place to connect with other professionals, share ideas, and learn from each other.\n",
            "\n",
            "5. Attend workshops and conferences: Attend workshops and conferences related to Gen AI to network with other professionals and learn about the latest trends and techniques in the field.\n",
            "\n",
            "6. Experiment with different tools: There are various Gen AI tools available in the market. Experiment with different tools to find the ones that work best for you and your projects.\n",
            "\n",
            "7. Collaborate with others: Collaborate with other professionals in the field to work on projects together. This will help\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"I want to open a shop for {name} industry. Suggest a fancy name for this.\"\n",
        ")\n",
        "prompt_template_name.format(name=\"clothing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6LWAF_xMzUtp",
        "outputId": "359406c6-9270-4377-c281-f3412bde3f18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to open a shop for clothing industry. Suggest a fancy name for this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"chain\" concept in Large Language Models (LLMs) like those used in LangChain refers to a series of linked operations or prompts that are executed sequentially to achieve a complex task. This concept is often referred to as \"chaining\" and it is used to break down a complicated process into smaller, manageable steps. Each step builds upon the previous one, creating a chain of operations that ultimately leads to the desired outcome."
      ],
      "metadata": {
        "id": "U1dD3ARu19GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "chain.run(\"Sweden\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GG1I2M7k1dPO",
        "outputId": "7d1ecf73-1f56-41ba-a65b-a6cab56c971e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\"Swedish Delights Bistro\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential chaining is a technique used with large language models (LLMs) to perform tasks that require multiple steps. It involves connecting several LLMs or LLM processes together in a specific order, where the output of one step becomes the input for the next.\n"
      ],
      "metadata": {
        "id": "Ntj39pWO89Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template=\"I want to open a resturant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables= ['resturant_name'],\n",
        "    template = \"\"\"Suggest some menu items for {resturant_name}. Rturn it as a comma seperated list\"\"\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
      ],
      "metadata": {
        "id": "6A7iC4zs8-hm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In SimpleSequentialChain it will just give you one output."
      ],
      "metadata": {
        "id": "44_O8hMHCXbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
        "response = chain.run(\"Sweden\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi1nyJzn--VF",
        "outputId": "085268f9-9d9d-48f0-e3d4-efc5b26631c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Roast leg of lamb\n",
            "2. Smoked salmon platter\n",
            "3. Honey-glazed ham\n",
            "4. Grilled marinated chicken\n",
            "5. Wild mushroom and barley soup\n",
            "6. Nordic-style meatballs\n",
            "7. Pickled herring platter\n",
            "8. Roasted root vegetables\n",
            "9. Viking stew with beef and potatoes\n",
            "10. Apple and cinnamon crumble for dessert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template=\"I want to open a resturant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"resturant_name\")\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables= ['resturant_name'],\n",
        "    template = \"Suggest some menu items for {resturant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ],
      "metadata": {
        "id": "8vyXbJiB_4YE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain, food_items_chain],\n",
        "    input_variables=[\"cuisine\"],\n",
        "    output_variables=[\"resturant_name\", \"menu_items\"]\n",
        ")\n",
        "response = chain({\"cuisine\": \"Sweden\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLYSkvSPDVmK",
        "outputId": "5bb21592-0437-42bb-b3c0-2c1ee3c87004"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'Sweden', 'resturant_name': '\\n\\n\"Svensk Matpalats\" (translates to \"Swedish Food Paradise\")', 'menu_items': ' \\n\\n1. Swedish Meatballs with Lingonberry Sauce\\n2. Gravlax (Cured Salmon) with Dill Mustard Sauce\\n3. Smörgåsbord Platter with various traditional Swedish dishes such as pickled herring, smoked salmon, and boiled potatoes\\n4. Janssons Frestelse (Swedish Potato and Anchovy Casserole)\\n5. Köttbullar (Swedish Meatball) Sandwich with Creamy Cucumber Salad\\n6. Pyttipanna (Swedish Hash) with Fried Eggs and Beetroot Relish\\n7. Raggmunk (Swedish Potato Pancakes) served with Lingonberry Jam\\n8. Kanelbullar (Cinnamon Buns) served with Coffee or Hot Chocolate\\n9. Grilled Beef Tenderloin with Creamy Mushroom Sauce and Potato Dumplings\\n10. Smörgåstårta (Swedish Sandwich Cake) with layers of bread, smoked salmon, shrimp, and creamy dill filling.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "# Prompt templates\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"destination\"],\n",
        "    template=\"I want to plan a travel package for {destination}. Suggest a fancy name for this package.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"package_name\")\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=['package_name'],\n",
        "    template=\"Suggest key attractions and activities for {package_name}.\"\n",
        ")\n",
        "\n",
        "attractions_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"attractions\")\n",
        "\n",
        "# Sequential chain\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain, attractions_chain],\n",
        "    input_variables=[\"destination\"],\n",
        "    output_variables=[\"package_name\", \"attractions\"]\n",
        ")\n",
        "\n",
        "# Get response from the chain\n",
        "response = chain({\"destination\": \"New Zealand\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9lt5iISD4x5",
        "outputId": "d0c6c123-563e-4cb4-d23a-b9a914902c12"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'destination': 'New Zealand', 'package_name': '\\n\\n\"Kiwi Adventure Escapade: Discover the Wonders of New Zealand\" ', 'attractions': \"\\n\\n1. Hiking in the Fiordland National Park: Explore the breathtaking landscapes, waterfalls, and native wildlife of this UNESCO World Heritage Site.\\n\\n2. Bungee Jumping in Queenstown: Experience the thrill of jumping off the historic Kawarau Bridge or the iconic Nevis Bungy, the highest bungee jump in New Zealand.\\n\\n3. Maori Cultural Experience: Learn about the indigenous Maori culture through traditional performances, hangi feasts, and visits to historical sites.\\n\\n4. Glacier Hiking in Franz Josef: Get up close and personal with the stunning Franz Josef Glacier on a guided hiking tour.\\n\\n5. Hobbiton Movie Set Tour: Visit the real-life movie set of Hobbiton from the beloved Lord of the Rings and Hobbit films.\\n\\n6. White Water Rafting on the Shotover River: Paddle through thrilling rapids and stunning canyons on one of New Zealand's most famous rivers.\\n\\n7. Wai-O-Tapu Thermal Wonderland: Witness the otherworldly geothermal wonders, including colorful hot springs and bubbling mud pools, at this geothermal park.\\n\\n8. Skydiving over Lake Taupo: Experience the ultimate rush as you freefall from a plane over the stunning Lake Taupo\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNOIwXiFLdWt",
        "outputId": "30510329-d6c5-4d9a-f96e-9481cd5516ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=839793c72852ff1f523110b008ec980558cfad1ee94f394b638695c3b9370ede\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "id": "YhdLd5VlPdc7",
        "outputId": "caec633a-a070-4746-8d8d-bd2fca6f8814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.6.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=0d0de27c59cff29bcc50cddf79b9b1cadfa2330a56b15bff577e08b821a8a92c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import VERBOSE\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
        "\n",
        "agent.run(\"When was Elon musk born? What is his age right now in 2023?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "fkc_wLKn_kb9",
        "outputId": "8d9e3fdf-bfae-4435-b24a-711eb05f659b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use wikipedia to find out information about Elon Musk.\n",
            "Action: wikipedia\n",
            "Action Input: \"Elon Musk\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
            "Summary: Elon Reeve Musk (; born June 28, 1971) is a businessman and investor known for his key roles in space company SpaceX and automotive company Tesla, Inc. Other involvements include ownership of X Corp., formerly Twitter, and his role in the founding of The Boring Company, xAI, Neuralink and OpenAI. He is one of the wealthiest people in the world; as of June 2024, Forbes estimates his net worth to be US$214 billion.\n",
            "Musk was born in Pretoria to Maye and Errol Musk and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999. That same year, Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. In October 2002, eBay acquired PayPal for $1.5 billion. Using $100 million of the money he made from the sale of PayPal, Musk founded SpaceX, a spaceflight services company, in 2002. \n",
            "In 2004, Musk was an early investor in electric vehicle manufacturer Tesla Motors, Inc. (later Tesla, Inc.). He became the company's chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and The Boring Company, a tunnel construction company. In 2018, the U.S. Securities and Exchange Commission (SEC) sued Musk, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, Musk founded xAI, an artificial intelligence company.\n",
            "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation, promoting right-wing conspiracy theories, and appearing to endorse antisemitic conspiracy theories, the latter of which he later apologized for. His ownership of Twitter has been similarly controversial, being marked by layoffs of large numbers of employees, an increase in hate speech, misinformation and disinformation posts on the website, and changes to Twitter Blue verification.\n",
            "\n",
            "\n",
            "\n",
            "Page: Twitter under Elon Musk\n",
            "Summary: Elon Musk completed his acquisition of Twitter in October 2022; Musk acted as CEO of Twitter until June 2023 when he was succeeded by Linda Yaccarino. Under Musk, Twitter was rebranded to X. It is one of the top social media platforms and the seventh-most visited website in the world. Users can share posts containing text messages, images, and videos and interact with other users' content through likes and reposts. X offers additional features such as direct messaging, video and audio calling, bookmarks, lists, communities, a chatbot, and the social audio feature Spaces.\n",
            "Founded in March 2006 by Jack Dorsey, Noah Glass, Biz Stone, and Evan Williams as Twitter, it underwent a rebranding in July 2023 after being acquired by Elon Musk in 2022. \n",
            "Now operating as X, the platform closely resembles its predecessor but includes additional features such as long-form texts,  account monetization option\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the Calculator to find out Elon Musk's age in 2023.\n",
            "Action: Calculator\n",
            "Action Input: \"2023 - 1971\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should subtract 1 from 52 since Elon Musk's birthday is in June.\n",
            "Action: Calculator\n",
            "Action Input: \"52 - 1\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 51\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should now add 2, since 2023 is 2 years away from the current year.\n",
            "Action: Calculator\n",
            "Action Input: \"51 + 2\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Elon Musk will be 53 years old in 2023.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Elon Musk will be 53 years old in 2023.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from security_serpapi_key import serpapi_key\n",
        "# Set the OPENAI_API_KEY environment variable\n",
        "import os\n",
        "os.environ['SERPAPI_API_KEY'] = serpapi_key"
      ],
      "metadata": {
        "id": "vqhtAXFDLP-A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zero-Shot Learning: The agent does not require task-specific training examples.\n",
        "Instead, it can understand and perform the task based on the description provided to it.\n",
        "\n",
        "Reasoning and Acting: The agent can reason about the task and make decisions or take actions\n",
        "based on the information and instructions it receives.\n",
        "\n",
        "AgentType.ZERO_SHOT_REACT_DESCRIPTION is a powerful approach for building versatile AI agents\n",
        "capable of understanding and performing tasks based on descriptions alone,\n",
        "leveraging zero-shot learning and reasoning capabilities. This makes it suitable for applications\n",
        " where tasks can be varied and are described dynamically."
      ],
      "metadata": {
        "id": "gIBeoB83STjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
        "\n",
        "agent.run(\"what was the GDP of US in 2022 plus 5?\")"
      ],
      "metadata": {
        "id": "04HTS4tCOQIa",
        "outputId": "35197cea-b358-4bb7-c8ef-222590871be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the Calculator tool to solve this math problem.\n",
            "Action: Calculator\n",
            "Action Input: 2022 + 5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2027\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I need to search for the GDP of the US in 2027.\n",
            "Action: Search\n",
            "Action Input: \"GDP of US in 2027\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'United States - Gross domestic product (GDP) 2029 - Statista', 'source': 'Statista'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: According to Statista, the GDP of the US in 2027 is projected to be $25.8 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to Statista, the GDP of the US in 2027 is projected to be $25.8 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
        "\n",
        "# Use a more explicit prompt to ensure the tool returns the GDP in USD.\n",
        "agent.run(\"What was the GDP of India in 2022 measured in US dollars? Give only the numerical value. After you find the value, add 5 to it.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ilvNAmJNQSBI",
        "outputId": "ed460a1d-bed7-4208-c708-f7b9dca8d989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a search engine to find the GDP of India in 2022.\n",
            "Action: Search\n",
            "Action Input: \"GDP of India in 2022 in US dollars\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mIndia. $3.417 trillion (2022 est.)\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to add 5 to the GDP value.\n",
            "Action: Calculator\n",
            "Action Input: 3.417 trillion + 5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3417000000005.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 3417000000005.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3417000000005.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memory"
      ],
      "metadata": {
        "id": "8h4Ea8erW855"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Germany\")\n",
        "print(name)"
      ],
      "metadata": {
        "id": "BhTzfiMBPYfz",
        "outputId": "08af3321-ad93-45bb-8c9e-5b9a74886db0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Enchanting Germany: A Luxurious Journey Through the Heart of Europe\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "id": "p0LqDGFvXCr7",
        "outputId": "37ac6443-1ea7-497e-d8af-8d7ca90b5761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Exotic India Escapade\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "gi5-a7ypXLN7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Why is it NoneType? Explicitly, we have to declare memory.\n",
        "type(chain.memory)"
      ],
      "metadata": {
        "id": "6XiS9mVEXQYD",
        "outputId": "1ea4e3c1-42c0-4635-bc61-f15ae963f20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ConversationBufferMemory"
      ],
      "metadata": {
        "id": "uayWol2DXs4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Germany\")\n",
        "print(name)"
      ],
      "metadata": {
        "id": "FLuCcbWyXpUz",
        "outputId": "8e621682-57c4-4c0d-f460-326e05575887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Enchanting Germany: A Luxurious Journey Through the Heart of Europe\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "id": "SUNFcSmRXzZK",
        "outputId": "d820ded3-7e2c-4e42-c047-e55588de41c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Exotic India Escapade\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#memory added\n",
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "id": "F8-Sg88QX3fh",
        "outputId": "42ceaaba-7e5b-46a4-c014-2f33fecdeb87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Germany\n",
            "AI: \n",
            "\n",
            "\"Enchanting Germany: A Luxurious Journey Through the Heart of Europe\"\n",
            "Human: Indian\n",
            "AI: \n",
            "\n",
            "\"Exotic India Escapade\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "jtozXWMnYi5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the 2011 Cricket World Cup?\")"
      ],
      "metadata": {
        "id": "zBwZjyeBX7wK",
        "outputId": "f58bfa86-7632-4f7c-c41c-86c7d1e450bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The 2011 Cricket World Cup was won by the Indian national cricket team. They beat Sri Lanka in the final match by six wickets. This was India's second time winning the World Cup, with their first win being in 1983. The match was played at the Wankhede Stadium in Mumbai, India. The Indian team was led by captain Mahendra Singh Dhoni and the man of the match was Yuvraj Singh. The winning moment was celebrated by millions of fans across India.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "id": "aORZKEL8YnWC",
        "outputId": "79fee9b2-cfba-4cfb-8e7f-4f3012f6c4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  The answer is 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k= 1 suggests storing only the most recent turn) of a conversation or dialogue, enabling the system to maintain context and provide more coherent responses over successive interactions.\n",
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "id": "zt7L2kViZPjJ",
        "outputId": "b73b17a9-2fb0-4e7a-868c-f3ece3a8b1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Again, I apologize but I still do not have enough information to answer your question. Could you provide me with more details or specify which winning team you are referring to?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3QPo24BZZSlI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}